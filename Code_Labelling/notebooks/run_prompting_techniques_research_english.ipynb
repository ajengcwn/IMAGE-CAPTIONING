{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ Gemini Mood Caption Generator - Research Execution (English)\n",
    "\n",
    "## Script to run automated English caption generation using 4 different prompting techniques:\n",
    "1. **Zero-Shot** - Direct instruction without examples\n",
    "2. **Few-Shot** - Instruction with example captions\n",
    "3. **Chain-of-Thought** - Step-by-step analysis approach\n",
    "4. **Persona** - Role-playing as an Influencer Specialist\n",
    "\n",
    "## Research Design:\n",
    "- **Dataset**: `data/raw/filenames_with_mood.csv`\n",
    "- **Images per mood**: 40 images\n",
    "- **Total unique images**: 120 images\n",
    "- **Processing**: Each image processed with 4 techniques\n",
    "- **Total captions**: 480 English captions\n",
    "- **Output**: `data/hasil_mood_captions_prompting_techniques_english.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import json\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üá∫üá∏ Configured for English caption generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('mood_caption_prompting_techniques_english.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set working directory to project root\n",
    "os.chdir('../../')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(\"‚úÖ Logging setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# RESEARCH CONFIGURATION\n",
    "# ==========================================\n",
    "API_KEY = \"AIzaSyABAI_PQAryjzvw7UIeStI_Lbl13douv04\"\n",
    "\n",
    "CONFIG = {\n",
    "    'csv_input': \"data/raw/filenames_with_mood.csv\",\n",
    "    'folder_gambar': \"scaled_images\",\n",
    "    'output_file': \"data/hasil_mood_captions_prompting_techniques_english.csv\",\n",
    "    'log_file': \"data/mood_processing_prompting_techniques_english_log.json\",\n",
    "    'selection_file': \"data/mood_prompting_techniques_english_selection.json\",\n",
    "    \n",
    "    # Research configuration - each image processed with 4 prompting techniques\n",
    "    'images_per_mood': 40,                # 40 images per mood for research\n",
    "    'total_unique_images': 120,           # 40 x 3 moods = 120 unique images\n",
    "    'total_captions': 480,                # 120 images x 4 techniques = 480 English captions\n",
    "    'random_seed': 42,                    # For reproducibility\n",
    "    \n",
    "    # Rate limiting for free tier\n",
    "    'base_delay': 2.0,\n",
    "    'max_delay': 20.0,\n",
    "    'retry_attempts': 3,\n",
    "    'batch_size': 1,\n",
    "    \n",
    "    # Memory management\n",
    "    'max_image_size': (1024, 1024),\n",
    "    'gc_interval': 5,\n",
    "    \n",
    "    # Mood configuration - according to filenames_with_mood.csv dataset\n",
    "    'moods': {\n",
    "        'mood_1': 'joy',\n",
    "        'mood_2': 'sad', \n",
    "        'mood_3': 'surprised'\n",
    "    },\n",
    "    \n",
    "    # Prompting techniques\n",
    "    'prompting_techniques': [\n",
    "        'zero-shot',\n",
    "        'few-shot', \n",
    "        'chain-of-thought',\n",
    "        'persona'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Gemini configuration\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "print(\"üé≠ Gemini Mood Caption Generator - English Research Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Dataset: {CONFIG['csv_input']}\")\n",
    "print(f\"üìä Images per mood: {CONFIG['images_per_mood']}\")\n",
    "print(f\"üìä Total unique images: {CONFIG['total_unique_images']}\")\n",
    "print(f\"üìä Total English captions: {CONFIG['total_captions']}\")\n",
    "print(f\"üìä Techniques: {', '.join(CONFIG['prompting_techniques'])}\")\n",
    "print(f\"üìä Moods: {', '.join(CONFIG['moods'].values())}\")\n",
    "print(f\"‚è±Ô∏è Estimated time: {CONFIG['total_captions'] * 3 / 60:.1f} minutes\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Configuration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ENGLISH PROMPTING TECHNIQUES FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def get_prompting_technique_prompt(mood: str, technique: str) -> str:\n",
    "    \"\"\"Generate optimized English prompt for specific mood using different prompting techniques\"\"\"\n",
    "    \n",
    "    prompting_techniques = {\n",
    "        \"zero-shot\": {\n",
    "            \"joy\": \"Create a short English caption for this image with a joyful and cheerful mood.\",\n",
    "            \"sad\": \"Create a short English caption for this image with a sad and melancholic mood.\",\n",
    "            \"surprised\": \"Create a short English caption for this image with a surprised and amazed mood.\"\n",
    "        },\n",
    "        \n",
    "        \"few-shot\": {\n",
    "            \"joy\": \"\"\"Follow the caption style based on these examples:\n",
    "            Mood: Joyful -> 'What an amazing day to start a new adventure! ‚ú®üòä'\n",
    "            Mood: Sad -> 'Sometimes silence is the best companion for reflection. üíôüòî'\n",
    "            Mood: Surprised -> 'Wow, this beauty is truly unexpected! üò±‚ú®'\n",
    "            \n",
    "            Now create an English caption for joyful mood ->\"\"\",\n",
    "            \n",
    "            \"sad\": \"\"\"Follow the caption style based on these examples:\n",
    "            Mood: Joyful -> 'What an amazing day to start a new adventure! ‚ú®üòä'\n",
    "            Mood: Sad -> 'Sometimes silence is the best companion for reflection. üíôüòî'\n",
    "            Mood: Surprised -> 'Wow, this beauty is truly unexpected! üò±‚ú®'\n",
    "            \n",
    "            Now create an English caption for sad mood ->\"\"\",\n",
    "            \n",
    "            \"surprised\": \"\"\"Follow the caption style based on these examples:\n",
    "            Mood: Joyful -> 'What an amazing day to start a new adventure! ‚ú®üòä'\n",
    "            Mood: Sad -> 'Sometimes silence is the best companion for reflection. üíôüòî'\n",
    "            Mood: Surprised -> 'Wow, this beauty is truly unexpected! üò±‚ú®'\n",
    "            \n",
    "            Now create an English caption for surprised mood ->\"\"\"\n",
    "        },\n",
    "        \n",
    "        \"chain-of-thought\": {\n",
    "            \"joy\": \"\"\"Analyze this image with the following steps:\n",
    "            1. Describe the main visual atmosphere in this image\n",
    "            2. Connect that atmosphere with joyful and happy emotions\n",
    "            3. Create one final English caption that best fits based on this analysis with a cheerful mood\"\"\",\n",
    "            \n",
    "            \"sad\": \"\"\"Analyze this image with the following steps:\n",
    "            1. Describe the main visual atmosphere in this image\n",
    "            2. Connect that atmosphere with sad and melancholic emotions\n",
    "            3. Create one final English caption that best fits based on this analysis with a sad mood\"\"\",\n",
    "            \n",
    "            \"surprised\": \"\"\"Analyze this image with the following steps:\n",
    "            1. Describe the main visual atmosphere in this image\n",
    "            2. Connect that atmosphere with surprised and amazed emotions\n",
    "            3. Create one final English caption that best fits based on this analysis with a surprised mood\"\"\"\n",
    "        },\n",
    "        \n",
    "        \"persona\": {\n",
    "            \"joy\": \"\"\"You are an Influencer Specialist who is expert in audience psychology and an experienced content creator. \n",
    "            Create a highly engaging English caption for this image with a joyful and cheerful impression that can increase engagement rate.\"\"\",\n",
    "            \n",
    "            \"sad\": \"\"\"You are an Influencer Specialist who is expert in audience psychology and an experienced content creator. \n",
    "            Create a highly engaging English caption for this image with a sad and melancholic impression that can touch the audience's heart.\"\"\",\n",
    "            \n",
    "            \"surprised\": \"\"\"You are an Influencer Specialist who is expert in audience psychology and an experienced content creator. \n",
    "            Create a highly engaging English caption for this image with a surprised and amazed impression that can captivate the audience.\"\"\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if technique in prompting_techniques and mood in prompting_techniques[technique]:\n",
    "        return prompting_techniques[technique][mood]\n",
    "    else:\n",
    "        return prompting_techniques[\"zero-shot\"].get(mood, prompting_techniques[\"zero-shot\"][\"joy\"])\n",
    "\n",
    "print(\"‚úÖ English prompting techniques functions defined!\")\n",
    "\n",
    "# Test prompting technique\n",
    "print(\"\\nüí° Example English prompts:\")\n",
    "for technique in CONFIG['prompting_techniques'][:2]:  # Show first 2 techniques\n",
    "    for mood in ['joy'][:1]:  # Show first mood\n",
    "        prompt = get_prompting_technique_prompt(mood, technique)\n",
    "        print(f\"\\nüîß {technique.upper()} - {mood.upper()}:\")\n",
    "        print(f\"   {prompt[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMAGE SELECTION FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def select_research_images(df_input: pd.DataFrame, config: Dict) -> Dict[str, List[str]]:\n",
    "    \"\"\"Select images for research - 40 images per mood, each processed with 4 techniques\"\"\"\n",
    "    \n",
    "    # Get all available images\n",
    "    all_available_files = []\n",
    "    for _, row in df_input.iterrows():\n",
    "        filename = row['filename']\n",
    "        image_path = os.path.join(config['folder_gambar'], filename)\n",
    "        if os.path.exists(image_path):\n",
    "            all_available_files.append(filename)\n",
    "    \n",
    "    logger.info(f\"üìä Total available images: {len(all_available_files)}\")\n",
    "    \n",
    "    # Check if we have enough images\n",
    "    total_needed = config['total_unique_images']\n",
    "    if len(all_available_files) < total_needed:\n",
    "        logger.warning(f\"‚ö†Ô∏è Not enough images! Available: {len(all_available_files)}, Needed: {total_needed}\")\n",
    "        # Adjust images per mood\n",
    "        adjusted_per_mood = len(all_available_files) // len(config['moods'])\n",
    "        logger.info(f\"üìä Adjusting to {adjusted_per_mood} images per mood\")\n",
    "        config['images_per_mood'] = adjusted_per_mood\n",
    "        config['total_unique_images'] = adjusted_per_mood * len(config['moods'])\n",
    "        config['total_captions'] = config['total_unique_images'] * len(config['prompting_techniques'])\n",
    "    \n",
    "    # Shuffle the list for random selection\n",
    "    random.shuffle(all_available_files)\n",
    "    \n",
    "    # Select images for each mood\n",
    "    mood_selections = {}\n",
    "    current_idx = 0\n",
    "    \n",
    "    for mood_name, mood_value in config['moods'].items():\n",
    "        end_idx = current_idx + config['images_per_mood']\n",
    "        selected_files = all_available_files[current_idx:end_idx]\n",
    "        \n",
    "        mood_selections[mood_name] = {\n",
    "            'mood_value': mood_value,\n",
    "            'files': selected_files\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"üé≠ {mood_name} ({mood_value}): Selected {len(selected_files)} images\")\n",
    "        logger.info(f\"   Sample files: {selected_files[:3]}...\")\n",
    "        \n",
    "        current_idx = end_idx\n",
    "    \n",
    "    # Save selection for reproducibility\n",
    "    selection_data = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'random_seed': config['random_seed'],\n",
    "        'images_per_mood': config['images_per_mood'],\n",
    "        'total_unique_images': config['total_unique_images'],\n",
    "        'total_captions': config['total_captions'],\n",
    "        'total_available': len(all_available_files),\n",
    "        'research_design': 'Each image processed with 4 English prompting techniques',\n",
    "        'language': 'English',\n",
    "        'selections': mood_selections\n",
    "    }\n",
    "    \n",
    "    with open(config['selection_file'], 'w') as f:\n",
    "        json.dump(selection_data, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"üíæ Selection saved to: {config['selection_file']}\")\n",
    "    \n",
    "    return mood_selections\n",
    "\n",
    "print(\"‚úÖ Image selection functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ENGLISH CAPTION PROCESSOR CLASS\n",
    "# ==========================================\n",
    "\n",
    "class EnglishPromptingTechniquesCaptionProcessor:\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.current_delay = config['base_delay']\n",
    "        self.success_count = 0\n",
    "        self.error_count = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Initialize stats for each technique\n",
    "        self.technique_stats = {}\n",
    "        for technique in config['prompting_techniques']:\n",
    "            self.technique_stats[technique] = {'success': 0, 'error': 0}\n",
    "        \n",
    "        random.seed(config['random_seed'])\n",
    "    \n",
    "    def load_and_optimize_image(self, image_path: str) -> Optional[Image.Image]:\n",
    "        \"\"\"Load and optimize image to reduce memory usage\"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Resize if too large\n",
    "            if img.size[0] > self.config['max_image_size'][0] or img.size[1] > self.config['max_image_size'][1]:\n",
    "                img.thumbnail(self.config['max_image_size'], Image.Resampling.LANCZOS)\n",
    "                logger.debug(f\"Resized image {image_path} to {img.size}\")\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            return img\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def adaptive_delay(self, success: bool):\n",
    "        \"\"\"Adaptive delay based on success rate\"\"\"\n",
    "        if success:\n",
    "            self.current_delay = max(self.config['base_delay'], self.current_delay * 0.98)\n",
    "        else:\n",
    "            self.current_delay = min(self.config['max_delay'], self.current_delay * 1.2)\n",
    "        \n",
    "        time.sleep(self.current_delay)\n",
    "    \n",
    "    def generate_english_mood_caption(self, img: Image.Image, mood: str, technique: str, filename: str) -> str:\n",
    "        \"\"\"Generate English caption for specific mood and technique with retry mechanism\"\"\"\n",
    "        prompt = get_prompting_technique_prompt(mood, technique)\n",
    "        \n",
    "        for attempt in range(self.config['retry_attempts']):\n",
    "            try:\n",
    "                response = self.model.generate_content([prompt, img])\n",
    "                result = response.text.strip()\n",
    "                \n",
    "                # Clean up result\n",
    "                if result.startswith('\"') and result.endswith('\"'):\n",
    "                    result = result[1:-1]\n",
    "                \n",
    "                logger.info(f\"‚úÖ {technique}-{mood} English caption success for {filename} (attempt {attempt + 1})\")\n",
    "                self.technique_stats[technique]['success'] += 1\n",
    "                self.adaptive_delay(True)\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"‚ö†Ô∏è {technique}-{mood} English caption failed for {filename} (attempt {attempt + 1}): {e}\")\n",
    "                \n",
    "                if attempt < self.config['retry_attempts'] - 1:\n",
    "                    wait_time = (2 ** attempt) * self.config['base_delay']\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    self.technique_stats[technique]['error'] += 1\n",
    "                    self.adaptive_delay(False)\n",
    "                    return f\"Error generating {technique}-{mood} English caption: {str(e)[:50]}...\"\n",
    "    \n",
    "    def process_image_with_all_techniques(self, filename: str, mood_name: str, mood_value: str) -> List[Dict]:\n",
    "        \"\"\"Process single image with all 4 English prompting techniques\"\"\"\n",
    "        results = []\n",
    "        image_path = os.path.join(self.config['folder_gambar'], filename)\n",
    "        \n",
    "        logger.info(f\"üñºÔ∏è Processing {filename} for mood {mood_value} with all 4 English techniques\")\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            logger.warning(f\"‚ùå Image not found: {image_path}\")\n",
    "            for technique in self.config['prompting_techniques']:\n",
    "                result = {\n",
    "                    'filename': filename,\n",
    "                    'mood_type': mood_value,\n",
    "                    'mood_column': mood_name,\n",
    "                    'prompting_technique': technique,\n",
    "                    'processing_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'image_exists': False,\n",
    "                    'processing_duration': 0,\n",
    "                    'success': False,\n",
    "                    'language': 'English',\n",
    "                    'caption': f\"Image not found: {filename}\"\n",
    "                }\n",
    "                results.append(result)\n",
    "            return results\n",
    "        \n",
    "        # Load image once for all techniques\n",
    "        img = self.load_and_optimize_image(image_path)\n",
    "        if img is None:\n",
    "            logger.warning(f\"‚ùå Failed to load image: {image_path}\")\n",
    "            for technique in self.config['prompting_techniques']:\n",
    "                result = {\n",
    "                    'filename': filename,\n",
    "                    'mood_type': mood_value,\n",
    "                    'mood_column': mood_name,\n",
    "                    'prompting_technique': technique,\n",
    "                    'processing_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'image_exists': True,\n",
    "                    'processing_duration': 0,\n",
    "                    'success': False,\n",
    "                    'language': 'English',\n",
    "                    'caption': f\"Failed to load image: {filename}\"\n",
    "                }\n",
    "                results.append(result)\n",
    "            return results\n",
    "        \n",
    "        # Process with each technique\n",
    "        for i, technique in enumerate(self.config['prompting_techniques']):\n",
    "            start_time = time.time()\n",
    "            logger.info(f\"  üîß Technique {i+1}/4: {technique} (English)\")\n",
    "            \n",
    "            # Generate English caption\n",
    "            caption = self.generate_english_mood_caption(img, mood_value, technique, filename)\n",
    "            \n",
    "            # Create result\n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'mood_type': mood_value,\n",
    "                'mood_column': mood_name,\n",
    "                'prompting_technique': technique,\n",
    "                'processing_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'image_exists': True,\n",
    "                'processing_duration': time.time() - start_time,\n",
    "                'success': not caption.startswith('Error'),\n",
    "                'language': 'English',\n",
    "                'caption': caption\n",
    "            }\n",
    "            \n",
    "            if result['success']:\n",
    "                self.success_count += 1\n",
    "            else:\n",
    "                self.error_count += 1\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        # Cleanup image\n",
    "        img.close()\n",
    "        del img\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_processing_stats(self) -> Dict:\n",
    "        \"\"\"Get current processing statistics\"\"\"\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        total_processed = self.success_count + self.error_count\n",
    "        \n",
    "        return {\n",
    "            'total_processed': total_processed,\n",
    "            'success_count': self.success_count,\n",
    "            'error_count': self.error_count,\n",
    "            'success_rate': self.success_count / max(total_processed, 1),\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'avg_time_per_image': elapsed_time / max(total_processed, 1),\n",
    "            'current_delay': self.current_delay,\n",
    "            'language': 'English',\n",
    "            'technique_stats': self.technique_stats\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ English caption processor class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# LOAD DATASET & PREPARE FOR PROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"üé≠ Gemini Mood Caption Generator - English Research Prompting Techniques Comparison\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä Research Design: Each image processed with 4 English prompting techniques\")\n",
    "print(f\"üìä Dataset: {CONFIG['csv_input']}\")\n",
    "print(f\"üìä Images per mood: {CONFIG['images_per_mood']}\")\n",
    "print(f\"üìä Total unique images: {CONFIG['total_unique_images']}\")\n",
    "print(f\"üìä Total English captions: {CONFIG['total_captions']}\")\n",
    "print(f\"üìä Techniques: {', '.join(CONFIG['prompting_techniques'])}\")\n",
    "print(f\"üìä Moods: {', '.join(CONFIG['moods'].values())}\")\n",
    "print(f\"‚è∞ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load dataset\n",
    "logger.info(f\"üìÇ Loading dataset: {CONFIG['csv_input']}\")\n",
    "df_input = pd.read_csv(CONFIG['csv_input'])\n",
    "logger.info(f\"üìä Dataset loaded: {len(df_input)} images available\")\n",
    "\n",
    "print(f\"\\nüìä Dataset Info:\")\n",
    "print(f\"   - Total images in dataset: {len(df_input)}\")\n",
    "print(f\"   - Dataset columns: {df_input.columns.tolist()}\")\n",
    "print(f\"   - Sample data:\")\n",
    "print(df_input.head())\n",
    "\n",
    "# Check images folder\n",
    "if os.path.exists(CONFIG['folder_gambar']):\n",
    "    image_files = [f for f in os.listdir(CONFIG['folder_gambar']) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"\\nüìä Available images in {CONFIG['folder_gambar']}: {len(image_files)}\")\n",
    "    print(f\"üìä Required images: {CONFIG['total_unique_images']}\")\n",
    "    print(f\"üìä Sufficient images: {'‚úÖ' if len(image_files) >= CONFIG['total_unique_images'] else '‚ùå'}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Images folder '{CONFIG['folder_gambar']}' not found!\")\n",
    "    print(f\"üí° Please create the folder and add your images there.\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset loaded and ready for English processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# EXECUTE ENGLISH RESEARCH PROCESSING\n",
    "# ==========================================\n",
    "# UNCOMMENT THE CODE BELOW TO START PROCESSING\n",
    "\n",
    "# # Initialize English processor\n",
    "# processor = EnglishPromptingTechniquesCaptionProcessor(CONFIG)\n",
    "\n",
    "# # Create research image selection\n",
    "# logger.info(\"üé≤ Creating research image selection for English captions...\")\n",
    "# mood_selections = select_research_images(df_input, CONFIG)\n",
    "\n",
    "# # Process each mood\n",
    "# all_results = []\n",
    "\n",
    "# for mood_name, mood_data in mood_selections.items():\n",
    "#     mood_value = mood_data['mood_value']\n",
    "#     selected_files = mood_data['files']\n",
    "    \n",
    "#     logger.info(f\"\\nüé≠ Processing mood: {mood_name} ({mood_value}) - {len(selected_files)} images for English captions\")\n",
    "    \n",
    "#     # Process each image with all 4 English techniques\n",
    "#     for i, filename in enumerate(tqdm(selected_files, desc=f\"Processing {mood_value} images (English)\")):\n",
    "#         logger.info(f\"\\nüì∏ Image {i+1}/{len(selected_files)}: {filename} (English)\")\n",
    "        \n",
    "#         # Process this image with all 4 English techniques\n",
    "#         image_results = processor.process_image_with_all_techniques(filename, mood_name, mood_value)\n",
    "#         all_results.extend(image_results)\n",
    "        \n",
    "#         # Save progress after every 5 images\n",
    "#         if (i + 1) % 5 == 0:\n",
    "#             temp_df = pd.DataFrame(all_results)\n",
    "#             temp_df.to_csv(CONFIG['output_file'], index=False)\n",
    "            \n",
    "#             # Save stats\n",
    "#             stats = processor.get_processing_stats()\n",
    "#             with open(CONFIG['log_file'], 'w') as f:\n",
    "#                 json.dump(stats, f, indent=2)\n",
    "            \n",
    "#             logger.info(f\"üíæ Progress saved: {len(all_results)} total English captions\")\n",
    "#             logger.info(f\"üìà Current success rate: {stats['success_rate']:.2%}\")\n",
    "        \n",
    "#         # Periodic garbage collection\n",
    "#         if (i + 1) % CONFIG['gc_interval'] == 0:\n",
    "#             gc.collect()\n",
    "#             logger.info(f\"üßπ Garbage collection performed\")\n",
    "\n",
    "print(\"\\nüí° Uncomment the code above to start English processing!\")\n",
    "print(\"üí° Make sure the 'scaled_images' folder contains your images\")\n",
    "print(\"üí° Processing will take approximately 24 minutes for 480 English captions\")\n",
    "print(\"üí° Results will be saved to:\", CONFIG['output_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# FINAL ENGLISH RESULTS SUMMARY\n",
    "# ==========================================\n",
    "# This cell will run after processing is complete\n",
    "\n",
    "# # Final summary\n",
    "# if all_results:\n",
    "#     final_df = pd.DataFrame(all_results)\n",
    "#     final_df.to_csv(CONFIG['output_file'], index=False)\n",
    "    \n",
    "#     final_stats = processor.get_processing_stats()\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(\"üéâ ENGLISH RESEARCH PROCESSING COMPLETED!\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(f\"üìä Total processed: {final_stats['total_processed']} English captions\")\n",
    "#     print(f\"üìä Unique images: {CONFIG['total_unique_images']}\")\n",
    "#     print(f\"‚úÖ Success: {final_stats['success_count']}\")\n",
    "#     print(f\"‚ùå Errors: {final_stats['error_count']}\")\n",
    "#     print(f\"üìà Overall success rate: {final_stats['success_rate']:.2%}\")\n",
    "#     print(f\"‚è±Ô∏è Total time: {final_stats['elapsed_time']/60:.1f} minutes\")\n",
    "#     print(f\"üá∫üá∏ Language: English\")\n",
    "    \n",
    "#     print(f\"\\nüîß Final Technique Breakdown:\")\n",
    "#     technique_summary = final_df['prompting_technique'].value_counts()\n",
    "#     for technique, count in technique_summary.items():\n",
    "#         print(f\"   {technique.capitalize()}: {count} English captions\")\n",
    "    \n",
    "#     # Final breakdown by mood\n",
    "#     print(f\"\\nüé≠ Final Mood Breakdown:\")\n",
    "#     mood_summary = final_df['mood_type'].value_counts()\n",
    "#     for mood, count in mood_summary.items():\n",
    "#         print(f\"   {mood.capitalize()}: {count} English captions\")\n",
    "    \n",
    "#     # Research analysis summary\n",
    "#     print(f\"\\nüìä English Research Summary:\")\n",
    "#     print(f\"   - Each of {CONFIG['total_unique_images']} images processed with 4 English techniques\")\n",
    "#     print(f\"   - Perfect for comparative analysis of English prompting techniques\")\n",
    "#     print(f\"   - Each technique tested on identical image set\")\n",
    "#     print(f\"   - All captions generated in English\")\n",
    "    \n",
    "#     print(f\"\\nüíæ English results saved to: {CONFIG['output_file']}\")\n",
    "#     print(f\"üé≤ Selection saved to: {CONFIG['selection_file']}\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     # Display sample results\n",
    "#     print(\"\\nüìä Sample English Results:\")\n",
    "#     print(final_df.head(10))\n",
    "\n",
    "print(\"\\n‚úÖ English notebook ready for execution!\")\n",
    "print(\"üí° Uncomment the processing code above to start the English research\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}